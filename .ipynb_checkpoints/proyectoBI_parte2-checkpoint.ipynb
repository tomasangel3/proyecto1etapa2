{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3nJXUz-PCv6"
   },
   "source": [
    "# Proyecto 1 Etapa 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4OKaSREQyMY"
   },
   "source": [
    "## Integrantes\n",
    "- Raul Rincon (Lider de negocio y lider de datos)- 202120414\n",
    "- Tomas Angel (Lider del proyecto y lider de negocio) - 202020366\n",
    "- Luis Felipe Dussán (Lider analitico)- 201912308"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9llU0LCBpuIc"
   },
   "source": [
    "## Tareas asignadas\n",
    "\n",
    "* Luis Felipe Dussan\n",
    "    * Modelo: Bag of words\n",
    "    * Resultados texto\n",
    "\n",
    "* Raul Santiago Rincon\n",
    "    * Modelo: KNN (k-nearest neighbors)\n",
    "    * Entendimiento negocio y analitico\n",
    "    * Entendimiento y preparacion de datos\n",
    "    * Video\n",
    "\n",
    "* Tomas Angel\n",
    "    *  Modelo: Naive Bayes\n",
    "    *  Entendimiento del negocio\n",
    "    *  Lider del proyecto\n",
    "    *  Organizacion y analisis documental\n",
    "    *  Mapa de actores\n",
    "    *  Preparacion de resultados\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5yPD-aFxPKai"
   },
   "source": [
    "## 1. Entendimiento del negocio y enfoque analítico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jndDEV0DQ4FE"
   },
   "source": [
    "## 1.1. Tabla con datos solicitados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6j0lvZLTRjok"
   },
   "source": [
    "\n",
    "\n",
    "* **Oportunidad / problema negocio:**\n",
    "El negocio quiere mejorar la experiencia turistica y aumentar el numero de visitantes en diferentes atracciones turisticas de Colombia a traves de la mejora continua de la experiencia de los visitantes al realizar un analisis de las reseñas recolectadas para cada sitio turistico. De este modo, los criterios de exito radican en identificar aquellas caracteristicas claves que hacen atractivo un destino turistico, la diferenciacion clara entre sitios con altas y bajas recomendaciones, mecanismos precisos para determinar la calificacion de un sitio por parte de los turistas y generar las estrategias efectivas para mejorar la popularidad de los sitios y fomentar el turismo.\n",
    "El proyecto puede tener un impacto significativo en Colombia, ya que un análisis efectivo puede llevar a la mejora y promoción de sitios turísticos, lo que podría aumentar el número de turistas tanto locales como extranjeros. Esto a su vez podría tener efectos positivos en la economía local, generando empleo y aumentando los ingresos por turismo.\n",
    "\n",
    "* **Enfoque analitico:**\n",
    "Implementar un modelo de aprendizaje automático para analizar los textos que se proporcionan con el objetivo de determinar los aspectos importantes en ellos y comparar en las reseñas y determinar que esta afectando el turismo frente a las opiniones negativas. Se planea usar análisis de sentimientos con el algoritmo como SVM para clasificar texto en diferentes categorias, Naive Bayes para clasificar texto en categorias predefinidas y KNN para encontrar caracteristicas comunes entre los diferentes textos.\n",
    "\n",
    "* **Organizacíon y rol dentro del enfoque con la oportunidad definida:**\n",
    "  - El Ministerio de Comercio, Industria y Turismo de Colombia se beneficiaría al tener información detallada sobre los factores que influyen en la popularidad de los sitios turísticos, lo que les permitiría desarrollar políticas y estrategias para promover el turismo.\n",
    "  - La Asociación Hotelera y Turística de Colombia y las cadenas hoteleras se beneficiarían al conocer las características que hacen atractivos los sitios turísticos, lo que les permitiría ofrecer paquetes y servicios más atractivos para los turistas.\n",
    "  - Los hoteles pequeños ubicados en diferentes municipios de Colombia se beneficiarían al poder identificar oportunidades de mejora en sus servicios y promocionarlos de manera más efectiva.\n",
    "\n",
    "* **Contacto con experto externo al proyecto y detalles de planeación:**\n",
    "\n",
    "\n",
    "  * Estudiantes de estadistica: Matias Bayona y Laura Rivera\n",
    "  * Fechas de reuniones:\n",
    "    - Reunion lanzamiento y planeacion: 18 Marzo - 7:00 PM\n",
    "    - Reunión de ideación: 21 Marzo - 4:00 PM\n",
    "    - Reuniones de seguimiento: 1, 2, 3 Abril - 8:00 PM\n",
    "    - Reunión de finalización: 5 Abril - 7:00 PM\n",
    "  * Canales : Grupo Whatsapp y reunión en zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBQ5MxPaSXor"
   },
   "source": [
    "## 2. Entendimiento y preparación de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvIazh6Ju2GB"
   },
   "source": [
    "#### 2.1. Preparacion de los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fhvNk3yEyEFx",
    "outputId": "0d22b44f-509e-4414-f4a9-5f0e62ef587d"
   },
   "outputs": [],
   "source": [
    "!pip install -q contractions\n",
    "!pip install -q -U\n",
    "!python -m spacy download es_core_news_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNt9OdQ-wJnC"
   },
   "outputs": [],
   "source": [
    "# Importacion de librerias necesarias\n",
    "\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "import contractions\n",
    "import unicodedata\n",
    "import inflect\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    ")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from joblib import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UaxctfDMw4sX"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9_fddKZnw5Hn",
    "outputId": "d77de011-ea86-4089-86cf-f20c3dd0d83c"
   },
   "outputs": [],
   "source": [
    "# Descargando las stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwAmc2acw-5f"
   },
   "outputs": [],
   "source": [
    "# Función para tokenizar las reseñas\n",
    "def tokenizer(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tll-fb-hUFHk"
   },
   "source": [
    "Preparacion de los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEVaJBUQxDHp"
   },
   "outputs": [],
   "source": [
    "# Cargamos los datos tipo1\n",
    "\n",
    "df_review = pd.read_csv(\"/content/tipo1_entrenamiento_estudiantes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M8AZn6nK6ZEa",
    "outputId": "05ba7c4a-7fd1-41d6-a872-7a5d5278e80e"
   },
   "outputs": [],
   "source": [
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "wHQlH_cL6cRd",
    "outputId": "10e854a9-5fe8-46d7-c93a-80d5fdaae45d"
   },
   "outputs": [],
   "source": [
    "df_review.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6pzViwIo6mOM",
    "outputId": "580c2573-ccfb-4a9e-a285-797ad266182b"
   },
   "outputs": [],
   "source": [
    "df_review[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfOVEDypDa7s",
    "outputId": "261cac83-4978-41f8-c4ca-c6baa511c6c7"
   },
   "outputs": [],
   "source": [
    "df_review[\"Class\"].value_counts(dropna=False, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkacKFaHENa7",
    "outputId": "c6cb8a37-1e85-44d9-81a8-6b6038809c99"
   },
   "outputs": [],
   "source": [
    "df_review.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "tx7RESipEUCX",
    "outputId": "deaca45c-c49b-4cb4-c3f3-6d07bbf05a4a"
   },
   "outputs": [],
   "source": [
    "# ENTENDIMIENTO DE LOS DATOS\n",
    "\n",
    "from scipy import stats as st\n",
    "\n",
    "textos = df_review.copy()\n",
    "textos['Conteo'] = [len(x) for x in textos['Review']]\n",
    "textos['Moda'] = [st.mode([len(x) for x in i.split(' ')])[0] for i in textos['Review']]\n",
    "textos['Max'] = [[max([len(x) for x in i.split(' ')])][0] for i in textos['Review']]\n",
    "textos['Min'] = [[min([len(x) for x in i.split(' ')])][0] for i in textos['Review']]\n",
    "\n",
    "textos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPqQcKUxtqsO"
   },
   "source": [
    "Podemos ver que existen valores atípicos en reviews donde podemos evidenciar que existen reseñas de 13933 palabras o palabras de 27 caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isrFPJzMOyr1",
    "outputId": "5995824c-1241-4cbc-e51c-3cac46c2e91b"
   },
   "outputs": [],
   "source": [
    "print(\"Cantidad de datos duplicados: \",df_review.duplicated().sum())\n",
    "df_review.drop_duplicates(inplace=True)\n",
    "print(\"Cantidad de datos duplicados después: \",df_review.duplicated().sum())\n",
    "\n",
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "ANWeI6LsRL8Y",
    "outputId": "a79bc1d5-2e30-4906-c5ce-5b262073c1ef"
   },
   "outputs": [],
   "source": [
    "ax = sns.countplot(x=\"Class\", hue=\"Class\", data=df_review, dodge=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWVbSDZYuYel"
   },
   "source": [
    "Con esta grafica podemos definir que existen linealidad en los datos ya que las reseñas con clasificacion de 1 son bastante pocas en comparacion a las de clasificacion 5, al tener mas de 2000 en conteo podemos tenerlo en cuenta al momento de desarrollar los modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CZgxjmGOR2I"
   },
   "outputs": [],
   "source": [
    "# Limpieza de datos\n",
    "import unicodedata\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remueve los caracteres de la lista de palabras tokenizadas que no esten en ASCII\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word is not None:\n",
    "            new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convierte todos los caracteres de la lista de palabras tokenizadas a minusculas\"\"\"\n",
    "    return [word.lower() for word in words]\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remueve la puntuacion de la lista de palabras tokenizadas\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word is not None:\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"\n",
    "    Esta función toma una lista de palabras y reemplaza cada número en la lista con su representación textual.\n",
    "    \"\"\"\n",
    "    p = inflect.engine()\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            word_as_text = p.number_to_words(word)\n",
    "            processed_words.append(word_as_text)\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "    return processed_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remueve las 'stop words' de la lista de palabras tokenizadas\"\"\"\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "def preprocessing(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    words = replace_numbers(words)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CXgYsaarankR"
   },
   "outputs": [],
   "source": [
    "df_review['Review'] = df_review['Review'].apply(contractions.fix)\n",
    "df_review['Palabras'] = df_review['Review'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yKNg2kcR5po3"
   },
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "     text = re.sub('<[^>]*>', '', text)\n",
    "     emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                            text)\n",
    "     text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "             ' '.join(emoticons).replace('-', ''))\n",
    "     return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mk1J3diW6CiO"
   },
   "outputs": [],
   "source": [
    "df_review['Review'] = df_review['Review'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Vt6Rhn-zISA",
    "outputId": "4a66419d-d8a5-4282-d5c0-d5183edf99d9"
   },
   "outputs": [],
   "source": [
    "df_review['Palabras'].dropna()\n",
    "df_review.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "Ap3ip4RIa3p2",
    "outputId": "25777891-716c-4888-ccb7-2ad95eb1f2ff"
   },
   "outputs": [],
   "source": [
    "df_review.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "EE-2eUSFKLNa",
    "outputId": "18f0667c-33d4-4c5d-9ae2-f2f237063c9f"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Suponiendo que df_review es tu DataFrame y 'Review' es la columna que quieres comprobar\n",
    "df_review['ContainsNumber'] = df_review['Review'].str.contains(r'\\d')\n",
    "\n",
    "# Muestra las reseñas que contienen números\n",
    "df_review[df_review['ContainsNumber']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DyoOGnB-9KBb"
   },
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "   return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whUBTidFuuaq"
   },
   "source": [
    "#### 2.2. Preparacion de los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bz88SlE_u75T"
   },
   "outputs": [],
   "source": [
    "# Importar los datos de prueba\n",
    "df_prueba = pd.read_csv(\"/content/particion_prueba_estudiantes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6KDuCnqwwS5j",
    "outputId": "eae3be31-1c42-4d9d-8519-da3535afcc72"
   },
   "outputs": [],
   "source": [
    "df_prueba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "9lL52vDIwXY7",
    "outputId": "aaf98d2a-4940-4290-a434-f67b92ca0b7a"
   },
   "outputs": [],
   "source": [
    "df_prueba.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iXyFcCPwtpM",
    "outputId": "88b3daa2-6f88-45b6-8eb4-879a05993a75"
   },
   "outputs": [],
   "source": [
    "# Revision de datos duplicados en el dataset de prueba\n",
    "\n",
    "print(\"Cantidad de datos duplicados: \",df_prueba.duplicated().sum())\n",
    "df_prueba.drop_duplicates(inplace=True)\n",
    "print(\"Cantidad de datos duplicados después: \",df_prueba.duplicated().sum())\n",
    "\n",
    "df_prueba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FY2MyRkOw7Hs"
   },
   "outputs": [],
   "source": [
    "# Limpieza de datos\n",
    "import unicodedata\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    \"\"\"Remueve los caracteres de la lista de palabras tokenizadas que no esten en ASCII\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word is not None:\n",
    "            new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def to_lowercase(words):\n",
    "    \"\"\"Convierte todos los caracteres de la lista de palabras tokenizadas a minusculas\"\"\"\n",
    "    return [word.lower() for word in words]\n",
    "\n",
    "def remove_punctuation(words):\n",
    "    \"\"\"Remueve la puntuacion de la lista de palabras tokenizadas\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word is not None:\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "def replace_numbers(words):\n",
    "    \"\"\"\n",
    "    Esta función toma una lista de palabras y reemplaza cada número en la lista con su representación textual.\n",
    "    \"\"\"\n",
    "    p = inflect.engine()\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            word_as_text = p.number_to_words(word)\n",
    "            processed_words.append(word_as_text)\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "    return processed_words\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"Remueve las 'stop words' de la lista de palabras tokenizadas\"\"\"\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "def preprocessing(words):\n",
    "    words = to_lowercase(words)\n",
    "    words = replace_numbers(words)\n",
    "    words = remove_punctuation(words)\n",
    "    words = remove_non_ascii(words)\n",
    "    words = remove_stopwords(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nOVgt8Atw_ws"
   },
   "outputs": [],
   "source": [
    "df_prueba['Review'] = df_prueba['Review'].apply(contractions.fix)\n",
    "df_prueba['Palabras'] = df_prueba['Review'].apply(word_tokenize)\n",
    "df_prueba['Palabras'].dropna()\n",
    "df_prueba['Palabras'] = df_prueba['Palabras'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "Il_goUvN2jxw",
    "outputId": "9c3cd1d4-ab86-4ef9-c473-7a7513629908"
   },
   "outputs": [],
   "source": [
    "df_prueba.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tz94qfxoxKyr"
   },
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "     text = re.sub('<[^>]*>', '', text)\n",
    "     emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                            text)\n",
    "     text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "             ' '.join(emoticons).replace('-', ''))\n",
    "     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxO92ZCM57W3"
   },
   "outputs": [],
   "source": [
    "lemmatizer = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def lemmatize_verbs(Palabras):\n",
    "    #Lemmatize verbs in list of tokenized words\n",
    "    doc = lemmatizer(\" \".join(Palabras))\n",
    "    return [token.lemma_ for token in doc]\n",
    "\n",
    "df_prueba['Palabras'] = df_prueba['Palabras'].apply(lemmatize_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "4XEWtlfx7kpO",
    "outputId": "ebd9f8c5-2c97-49b9-acba-9e9bf88f4308"
   },
   "outputs": [],
   "source": [
    "df_prueba.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHilTHEJSc-g"
   },
   "source": [
    "## 3. Modelado y evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd_-6fli1Ml9"
   },
   "source": [
    "### 3.1. Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VHhfIFROuMF"
   },
   "source": [
    "#### Utilizando TF-IDF Vectorizer  (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5pOd_9rSCLUW",
    "outputId": "2a95ff67-8bb6-46a8-eb12-317f4728b117"
   },
   "outputs": [],
   "source": [
    "\n",
    "nltk.download('stopwords')\n",
    "#After we download the stop-words set, we can load and apply the English stop-word set as follows:\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('spanish')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sL6ulewD-6Lb"
   },
   "outputs": [],
   "source": [
    "X_train = df_review.loc[:3902, 'Review'].values\n",
    "y_train = df_review.loc[:3902, 'Class'].values\n",
    "X_test = df_review.loc[3902:, 'Review'].values\n",
    "y_test = df_review.loc[3902:, 'Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Xeoq1JpuA8C9",
    "outputId": "263265a2-a74a-41c5-8943-e7a69f3364c5"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                       lowercase=False,\n",
    "                        preprocessor=None)\n",
    "param_grid = [{'vect__ngram_range': [(1,1)],\n",
    "              'vect__stop_words': [stop, None],\n",
    "              'vect__tokenizer': [tokenizer,\n",
    "                                 tokenizer_porter],\n",
    "             'clf__penalty': ['l1', 'l2'],\n",
    "                'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1,1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer,\n",
    "                                   tokenizer_porter],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "              'clf__C': [1.0, 10.0, 100.0]}\n",
    "            ]\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                  ('clf',\n",
    "                       LogisticRegression(random_state=0,\n",
    "                                          solver='liblinear'))])\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                            scoring='accuracy',\n",
    "                            cv=5, verbose=2,\n",
    "                           n_jobs=1)\n",
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0n2-x2EYrtIP",
    "outputId": "e1d41eb9-604b-4be4-dd8a-385645d21862"
   },
   "outputs": [],
   "source": [
    "print(\"Best parameter set: %s\" % str(gs_lr_tfidf.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tVwFA1lyuivW",
    "outputId": "31c7ff45-fb93-4da5-fcf0-34aba7980628"
   },
   "outputs": [],
   "source": [
    "print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WkkvE5ouii-",
    "outputId": "bf57586a-e358-4786-da3a-236c1f45729f"
   },
   "outputs": [],
   "source": [
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Test Accuracy: %.3f'   % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jjcik5v8YQvX",
    "outputId": "c9c97721-4187-4be0-8d5c-c447b16ab0a1"
   },
   "outputs": [],
   "source": [
    "y_pred = gs_lr_tfidf.predict(X_test)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall del modelo:\", recall)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbPOD_tgYX6h",
    "outputId": "7edaaa18-e509-4bc9-a292-b353b4ee40f3"
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "ZoImU1w-Yeqh",
    "outputId": "bd2e7e89-9236-4416-8604-a1b2749eedc2"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusion\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-PB6vI4O3zq"
   },
   "source": [
    "#### Utilizando Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OLz-3GLCe39J",
    "outputId": "ec82c6d1-ba0a-48ee-a316-f26057cc29f4"
   },
   "outputs": [],
   "source": [
    "countV = CountVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]}\n",
    "            ]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', countV),\n",
    "                     ('clf', LogisticRegression(random_state=0, solver='liblinear'))])\n",
    "\n",
    "gs_lr_cv = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5, verbose=2,\n",
    "                           n_jobs=1)\n",
    "gs_lr_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TvtozlQCna3t",
    "outputId": "b602aaa2-47dc-44d3-abd6-2ed5ccf5be3c"
   },
   "outputs": [],
   "source": [
    "print(\"Best parameter set: %s\" % str(gs_lr_cv.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZn-xhYrng-l",
    "outputId": "0f47b590-8f2b-494d-e543-016ad364ac46"
   },
   "outputs": [],
   "source": [
    "print('CV Accuracy: %.3f' % gs_lr_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcspqfxUnkjz",
    "outputId": "95aceb62-2d2b-4493-8b2a-beaf338fce7b"
   },
   "outputs": [],
   "source": [
    "clf = gs_lr_cv.best_estimator_\n",
    "print('Test Accuracy: %.3f'   % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1HMGMMvYI7H",
    "outputId": "9ddf48d6-0a16-453c-81a5-3cc20239603e"
   },
   "outputs": [],
   "source": [
    "y_pred = gs_lr_cv.predict(X_test)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall del modelo:\", recall)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VghJhENHYMYG",
    "outputId": "e6af716b-9cb0-4884-88ad-f6abe9723dd9"
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "3BVjP45hYc84",
    "outputId": "68d93d33-9c72-4494-f79e-f4b04400899b"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusion\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ynv9dA52uQeh"
   },
   "source": [
    "#### Utilizando TF-IDF TRANSFORMER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZM4rrP8FEbmT",
    "outputId": "79e65154-a2ac-4783-8eb3-98794fb61273"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [stop, None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'tfidf__use_idf': [True, False],\n",
    "               'tfidf__norm': ['l1', 'l2'],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]}]\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', LogisticRegression(random_state=0, solver='liblinear'))])\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=5, verbose=2,\n",
    "                           n_jobs=1)\n",
    "gs_lr_tfidf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qbJ2EN12JnvT",
    "outputId": "59c9355b-ffca-408b-87a5-f2f810f965af"
   },
   "outputs": [],
   "source": [
    "print(\"Best parameter set: %s\" % str(gs_lr_tfidf.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIsD40JwPG2G",
    "outputId": "ad03ee00-325c-4c9a-f1ae-6e8e0a3404da"
   },
   "outputs": [],
   "source": [
    "print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wgN3MgD2W7Ta",
    "outputId": "1afa001b-1628-4fb5-d205-350d2bc5f49f"
   },
   "outputs": [],
   "source": [
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Test Accuracy: %.3f'   % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNnbjnNfXVBu",
    "outputId": "d404d5ec-5f8c-4e4b-ae58-ae51fef4d4bf"
   },
   "outputs": [],
   "source": [
    "y_pred = gs_lr_tfidf.predict(X_test)\n",
    "\n",
    "# Calcular las métricas de evaluación\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Imprimir las métricas de evaluación\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Recall del modelo:\", recall)\n",
    "print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-S3yck3-X8cY",
    "outputId": "815a6b64-ed71-4515-941c-02aaf41f1318"
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "AIsjlY6VYAj6",
    "outputId": "a616367f-a392-4145-ec36-968f79772bde"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusion\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "05-Ixx7-ggje"
   },
   "source": [
    "Basado en los resultados de precisión (accuracy) obtenidos para cada modelo, parece que el modelo construido con TF-IDF Transformer tuvo el mejor desempeño con un accuracy de 0.478, seguido por el modelo construido con TF-IDF Vectorizer con un accuracy de 0.476, y finalmente el modelo construido con Count Vectorizer con un accuracy de 0.457.\n",
    "\n",
    "Esto sugiere que el TF-IDF Transformer puede haber capturado mejor la información relevante en los datos de texto en comparación con los otros dos métodos de vectorización. Sin embargo, es importante considerar otras métricas de evaluación , como la de F1 Score . La cual nos arroja que TFIDF Transformer tiene el score más alto con 0,47, seguido de 0,46 de Tfidf Vectorizer y por último CountVectorizer con 0,45 en el F1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GY7I3Heh426o"
   },
   "source": [
    "### 3.2. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g99mxLswHPDF"
   },
   "source": [
    "#### Utilizando TFIDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-zdtWxWpPpp",
    "outputId": "1e65b674-e0a1-42cb-b669-3eae425c74bb"
   },
   "outputs": [],
   "source": [
    "# Dividir el DataFrame en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_review['Review'], df_review['Class'], test_size=0.3, random_state=42)\n",
    "\n",
    "# Convertir el texto en características numéricas usando TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Entrenar el modelo Naive Bayes\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predecir las clases para el conjunto de prueba\n",
    "y_pred = nb_classifier.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall del modelo: \", recall)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_l8AE9siABKS",
    "outputId": "1656d1a9-874d-4124-f2db-79775ec18d1e"
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "yBUZgVxlGew8",
    "outputId": "f80ef18c-1ade-4c09-d0ec-6a1e2b405d10"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusion\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDdOMGKiHxFy"
   },
   "source": [
    "#### Utilizando Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hY_KRbHLH2GF",
    "outputId": "f05afee6-d7b1-430c-a47c-4f39a0170f57"
   },
   "outputs": [],
   "source": [
    "# Características (texto de las reseñas)\n",
    "X = df_review['Review']\n",
    "\n",
    "# Etiquetas (clase de la reseña, 5 para buena, 0 para mala)\n",
    "y = df_review['Class']\n",
    "\n",
    "#Division de los textos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Predecir las clases para el conjunto de prueba\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall del modelo: \", recall)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D2e2VtgfIYfD",
    "outputId": "47ea292e-5799-4d47-f98e-e9ca5f055e87"
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "MIRh-Qx8I4qc",
    "outputId": "44418c1a-0505-4585-9606-4ac28603cd56"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusion\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcAmxCF847hD"
   },
   "source": [
    "### 3.3. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYe0GrxpCkhX"
   },
   "source": [
    "#### Utilizando TF-IDF (Term Frequency-Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "_-kTZPVz3icB",
    "outputId": "5e026f6f-c462-4350-a4ce-418282d7cf2c"
   },
   "outputs": [],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsFXk_-4ycND"
   },
   "outputs": [],
   "source": [
    "vectorizador = TfidfVectorizer(max_features=2500,min_df=7, max_df=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "6IePTDvpyH9Z",
    "outputId": "370180f0-1a3a-4163-d984-fe6a41c3400c"
   },
   "outputs": [],
   "source": [
    "df_knn = df_review.copy()\n",
    "# Se selecciona la variable objetivo\n",
    "Y = df_knn['Class']\n",
    "tfidf_wm_knn = vectorizador.fit_transform(df_knn[\"Review\"])\n",
    "df_final = pd.DataFrame(data = tfidf_wm_knn.toarray(),index = df_knn.index,columns = vectorizador.get_feature_names_out())\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "HDtp2a_wlLEp",
    "outputId": "8d1dc3fe-d749-4d2a-b461-2b6cf9c9bb09"
   },
   "outputs": [],
   "source": [
    "df_pca = df_final.copy()\n",
    "pca = PCA()\n",
    "pca.fit(df_pca)\n",
    "variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = np.cumsum(variance_ratio)\n",
    "plt.plot(cumulative_variance_ratio)\n",
    "plt.xlabel('Número de componentes principales')\n",
    "plt.ylabel('Variación acumulada')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "QgPjVYIbyzaG",
    "outputId": "32b3eaa2-5d22-4c20-9ec7-9062060a5420"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1750)\n",
    "transformados = pca.fit_transform(df_pca)\n",
    "df_pca = pd.DataFrame(\n",
    "    data=transformados,\n",
    "    columns=['PC'+str(x) for x in range(1750)])\n",
    "pd.concat([df_pca, Y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "dFCrKw8JVyKR",
    "outputId": "fbd677ea-d2a2-4798-86a3-6a3c6c794911"
   },
   "outputs": [],
   "source": [
    "df_pca = df_pca.dropna()\n",
    "df_pca.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "v3WyE2-z0FI2",
    "outputId": "b47d0568-7928-4798-f5dd-f93c30d721b4"
   },
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pca, Y, test_size=0.4, random_state=0, shuffle=True)\n",
    "for i in range(1,40):\n",
    " knn = KNeighborsClassifier(n_neighbors=i)\n",
    " knn.fit(X_train,y_train)\n",
    " pred_i = knn.predict(X_test)\n",
    " error_rate.append(np.mean(pred_i != y_test))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed',\n",
    "         marker='o',markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "print(\"Minimum error:-\",min(error_rate),\"at K =\",error_rate.index(min(error_rate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "9w942yv809Qd",
    "outputId": "da5ac813-8031-4c95-d782-36a6b3f81455"
   },
   "outputs": [],
   "source": [
    "#Grafico para visualizar en que valor de k se obtiene la precision mas alta, se puede ver que coincide con el grafico del error\n",
    "scores = []\n",
    "k_values = [i for i in range (1,40)]\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    score = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "    scores.append(np.mean(score))\n",
    "sns.lineplot(x = k_values, y = scores, marker = 'o')\n",
    "plt.xlabel(\"K Values\")\n",
    "plt.ylabel(\"Accuracy Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTeKpcdW1owc",
    "outputId": "e65a6667-18d6-43fc-e260-1bb6613fa58d"
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=38)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oXe5KFATTJ3T",
    "outputId": "1646b152-54f2-41b5-bce5-2a235825a155"
   },
   "outputs": [],
   "source": [
    "# Características (texto de las reseñas)\n",
    "X = df_review['Review']\n",
    "\n",
    "# Etiquetas (clase de la reseña, 5 para buena, 0 para mala)\n",
    "y = df_review['Class']\n",
    "\n",
    "#Division de los textos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_vec = vectorizador.fit_transform(X_train)\n",
    "knn = KNeighborsClassifier(n_neighbors=38)\n",
    "knn.fit(X_train_vec, y_train)\n",
    "X_test_vec = vectorizador.transform(X_test)\n",
    "\n",
    "# Predecir las clases para el conjunto de prueba\n",
    "y_pred = knn.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Recall del modelo: \", recall)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOHIHgJ3Vtbt",
    "outputId": "50298c36-f370-406a-919a-dad54d1c928c"
   },
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "ZExNzUxwVhX-",
    "outputId": "17436bc1-b2d0-41cc-c7f0-57778e6fdea3"
   },
   "outputs": [],
   "source": [
    "# Matriz de confusion\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJIcTOAySf4b"
   },
   "source": [
    "## 4. Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAH0acCI48Bd"
   },
   "source": [
    "### Analisis de los modelos segun su F1 score\n",
    "\n",
    "Al realizar los diferentes algoritmos (bag of words, naive bayes y KNN), se sacaron diferentes metricas para medir el rendimiento del modelo realizado y saber cual usar para los datos no etiquetados. En nuestro caso, consideramos que la metrica mas importante para tomar esta decision era la del F1 score. Esta es una medida de precisión de un modelo de clasificación que combina la precisión y el recall en una sola métrica y se calcula como la media armónica de la precisión y el recall. La precision hace referencia a que tan bien se ajusta el modelo a los datos reales, mientras que el recall (también conocido como sensibilidad o tasa positiva verdadera) es una métrica de evaluación de modelos de clasificación que mide la proporción de casos positivos reales que el modelo identifica correctamente de entre todos los casos positivos reales en los datos. Con esto en mente, se puede evidenciar que el modelo con mejor ajuste es el de Naive Bayes con count vectorizer, dando un f1 score de 0.4823.\n",
    "\n",
    "Para el conjunto de datos no etiquetados, realizamos un modelado de los reseñas usando Naive Bayes y count vectorizer para predecir la calificacion de la reseña. Dichos resultados se ven a continuacion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKlnzPAI5Nq8"
   },
   "source": [
    "### Ejecucion de 'Naive Bayes' con datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "mGzF6eE75Szd",
    "outputId": "cda639d4-809a-4b64-dd95-6aa3ff6b862c"
   },
   "outputs": [],
   "source": [
    "# Características del nuevo dataset (texto de las reseñas)\n",
    "X_prueba = df_prueba['Review']\n",
    "y_prueba = df_prueba.get('Class', None)\n",
    "\n",
    "# Transformar el texto usando el mejor vectorizador usado en el entrenamiento (CV)\n",
    "X_prueba_vec = vectorizer.transform(X_prueba)\n",
    "\n",
    "# Predecir las clases para el conjunto de prueba\n",
    "y_pred_prueba = clf.predict(X_prueba_vec)\n",
    "\n",
    "# Crear un DataFrame con las predicciones\n",
    "resultados_prueba = pd.DataFrame({\n",
    "    'Review': X_prueba,\n",
    "    'Class': y_pred_prueba\n",
    "      })\n",
    "\n",
    "resultados_prueba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "Oi4WGI7q2I55",
    "outputId": "23c33d30-62ea-491d-809b-2d4d4999d419"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "resultados_prueba['Prediccion'].plot(kind='hist', bins=20, title='Prediccion')\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blYvUNs7-6Vb"
   },
   "outputs": [],
   "source": [
    "# Generacion del archivo .csv con las predicciones de las resenias\n",
    "df_prueba.to_csv('resultados_prueba.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guRJPp2DTF-m"
   },
   "source": [
    "## 5. Mapa de actores relacionado con el producto de datos creados\n",
    "\n",
    "**Tabla con el mapa de actores relacionados con el producto de datos creados**\n",
    "\n",
    "  | Rol dentro de la empresa | Tipo de actor | Beneficio | Riesgo |\n",
    "  | - | - | - | - |\n",
    "  | Ministerio de Comercio, Industria y Turismo de Colombia | Financiador | Puede utilizar la información para desarrollar políticas y estrategias que promuevan el turismo en Colombia | Si el modelo no tiene un buen desempeño, las políticas y estrategias pueden basarse en información incorrecta, lo que podría no tener el efecto deseado en el turismo |\n",
    "  | Asociación Hotelera y Turística de Colombia (COTELCO) | Usuario-Cliente | Puede utilizar los resultados para mejorar la calidad de los servicios turísticos y promover destinos turísticos específicos | Si el modelo no funciona correctamente, las estrategias de promoción podrían dirigirse incorrectamente, lo que podría afectar la reputación de los destinos turísticos |\n",
    "  | Cadenas hoteleras (Hilton, Hoteles Estelar, Holiday Inn, etc.) | Beneficiario | Pueden utilizar la información para adaptar sus servicios y promociones a las preferencias de los turistas | Si el modelo no es preciso, las adaptaciones de servicios y promociones podrían no ser efectivas, lo que podría afectar su competitividad en el mercado |\n",
    "  | Hoteles pequeños en diferentes municipios de Colombia | Beneficiario | Pueden mejorar sus servicios y promocionarse de manera más efectiva, lo que puede aumentar su popularidad entre los turistas | Si el modelo no funciona correctamente, las mejoras en los servicios y la promoción podrían no ser adecuadas, lo que podría no tener el efecto deseado en la atracción de turistas |\n",
    "  | Turistas locales y extranjeros | Usuario-Cliente | Pueden beneficiarse al recibir recomendaciones más precisas y adaptadas a sus preferencias individuales | Si el modelo no es preciso, las recomendaciones pueden no ser relevantes para los turistas, lo que podría afectar su experiencia de viaje |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpuFkcT1aPdx"
   },
   "source": [
    "## 6. Construccion del pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PFHi3-bamKI"
   },
   "source": [
    "### 6.1. Pipleine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jk6t4YwwdWfS"
   },
   "outputs": [],
   "source": [
    "X_pl = df_review['Review']\n",
    "y_pl = df_review['Class']\n",
    "\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "model.fit(X_pl, y_pl)\n",
    "\n",
    "X_test = df_prueba['Review']\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "df_prueba['Class'] = y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPGS9X3bapCA"
   },
   "source": [
    "### 6.2. Exportacion del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwgSdRvDeqDh"
   },
   "outputs": [],
   "source": [
    "dump(pipeline, 'predictedReviews.joblib')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
